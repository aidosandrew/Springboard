{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Analysis of Robinhood Popularity Data - Pre-Processing\n",
    "\n",
    "Purpose: In this module, we pick up from Part Two - where we explored the data and added features to the dataset.\n",
    "\n",
    "Our goal in Part Three of Pre-Processing, we will prepare the data for our machine learning models.\n",
    "\n",
    "This may involve creating dummy features if appropriate, scaling the dataset, and splitting the data between the test and traing data.\n",
    "\n",
    "We also want to use some techniques from our EDA work again to check if there any issues (collinerity) in the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing modules for data pre-processing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        Date  Robinhood      Price    Volume Ticker Company  \\\n",
      "0           0  2018-07-02   150897.0  46.794998  70925200   AAPL   Apple   \n",
      "1           1  2018-07-03   151073.0  45.980000  55819200   AAPL   Apple   \n",
      "2           2  2018-07-05   151258.0  46.349998  66416800   AAPL   Apple   \n",
      "3           3  2018-07-06   151150.0  46.992500  69940800   AAPL   Apple   \n",
      "4           4  2018-07-09   150664.0  47.645000  79026400   AAPL   Apple   \n",
      "\n",
      "   Percentage_Volume  ExPost_PriceChange_1D  ExPost_PriceChange_5D  ...  \\\n",
      "0           0.002128                    NaN                    NaN  ...   \n",
      "1           0.002706              -0.017416                    NaN  ...   \n",
      "2           0.002277               0.008047                    NaN  ...   \n",
      "3           0.002161               0.013862                    NaN  ...   \n",
      "4           0.001907               0.013885                    NaN  ...   \n",
      "\n",
      "   ExPost_PriceChange_1D_Lag2  ExPost_PriceChange_1D_Lag3  \\\n",
      "0                         NaN                         NaN   \n",
      "1                         NaN                         NaN   \n",
      "2                         NaN                         NaN   \n",
      "3                   -0.017416                         NaN   \n",
      "4                    0.008047                   -0.017416   \n",
      "\n",
      "   ExPost_PriceChange_1D_Lag4  ExPost_PriceChange_1D_Lag5  \\\n",
      "0                         NaN                         NaN   \n",
      "1                         NaN                         NaN   \n",
      "2                         NaN                         NaN   \n",
      "3                         NaN                         NaN   \n",
      "4                         NaN                         NaN   \n",
      "\n",
      "   ExPost_PriceChange_1D_Lag6  ExPost_PriceChange_1D_Lag7    SMA_3D  SMA_5D  \\\n",
      "0                         NaN                         NaN       NaN     NaN   \n",
      "1                         NaN                         NaN       NaN     NaN   \n",
      "2                         NaN                         NaN       NaN     NaN   \n",
      "3                         NaN                         NaN  0.001498     NaN   \n",
      "4                         NaN                         NaN  0.011931     NaN   \n",
      "\n",
      "   SMA_10D  Expanded_Mean  \n",
      "0      NaN            NaN  \n",
      "1      NaN            NaN  \n",
      "2      NaN      -0.004685  \n",
      "3      NaN       0.001498  \n",
      "4      NaN       0.004594  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "['AAPL', 'AMD', 'AMZN', 'BABA', 'FB', 'GOOGL', 'INTC', 'JPM', 'MSFT', 'NFLX', 'NKE', 'NVDA', 'PYPL', 'SQ', 'SNAP', 'T', 'TSLA', 'TWTR', 'V', 'ZNGA']\n"
     ]
    }
   ],
   "source": [
    "# Let's read in our new dataset from Part Two\n",
    "\n",
    "filepath = '../data/stock_data_new.csv'\n",
    "df = pd.read_csv(filepath)\n",
    "print(df.head())\n",
    "\n",
    "# Let's also get a list of the stock basket tickers\n",
    "filepath = '../data/stock_info.csv'\n",
    "stock = pd.read_csv(filepath)\n",
    "tickers = stock['Ticker'].tolist()\n",
    "print(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10060 entries, 0 to 10059\n",
      "Data columns (total 43 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  10060 non-null  int64  \n",
      " 1   Date                        10060 non-null  object \n",
      " 2   Robinhood                   10060 non-null  float64\n",
      " 3   Price                       10060 non-null  float64\n",
      " 4   Volume                      10060 non-null  int64  \n",
      " 5   Ticker                      10060 non-null  object \n",
      " 6   Company                     10060 non-null  object \n",
      " 7   Percentage_Volume           10060 non-null  float64\n",
      " 8   ExPost_PriceChange_1D       10040 non-null  float64\n",
      " 9   ExPost_PriceChange_5D       9960 non-null   float64\n",
      " 10  ExPost_PriceChange_10D      9860 non-null   float64\n",
      " 11  ExAnte_PriceChange_1D       10040 non-null  float64\n",
      " 12  ExAnte_PriceChange_3D       10000 non-null  float64\n",
      " 13  ExAnte_PriceChange_5D       9960 non-null   float64\n",
      " 14  Year                        10060 non-null  int64  \n",
      " 15  Month                       10060 non-null  int64  \n",
      " 16  Day                         10060 non-null  int64  \n",
      " 17  Day_of_Week                 10060 non-null  int64  \n",
      " 18  Robinhood_Lag1              10040 non-null  float64\n",
      " 19  Robinhood_Lag2              10020 non-null  float64\n",
      " 20  Robinhood_Lag3              10000 non-null  float64\n",
      " 21  Robinhood_Lag4              9980 non-null   float64\n",
      " 22  Robinhood_Lag5              9960 non-null   float64\n",
      " 23  Robinhood_Lag6              9940 non-null   float64\n",
      " 24  Robinhood_Lag7              9920 non-null   float64\n",
      " 25  Percentage_Volume_Lag1      10040 non-null  float64\n",
      " 26  Percentage_Volume_Lag2      10020 non-null  float64\n",
      " 27  Percentage_Volume_Lag3      10000 non-null  float64\n",
      " 28  Percentage_Volume_Lag4      9980 non-null   float64\n",
      " 29  Percentage_Volume_Lag5      9960 non-null   float64\n",
      " 30  Percentage_Volume_Lag6      9940 non-null   float64\n",
      " 31  Percentage_Volume_Lag7      9920 non-null   float64\n",
      " 32  ExPost_PriceChange_1D_Lag1  10020 non-null  float64\n",
      " 33  ExPost_PriceChange_1D_Lag2  10000 non-null  float64\n",
      " 34  ExPost_PriceChange_1D_Lag3  9980 non-null   float64\n",
      " 35  ExPost_PriceChange_1D_Lag4  9960 non-null   float64\n",
      " 36  ExPost_PriceChange_1D_Lag5  9940 non-null   float64\n",
      " 37  ExPost_PriceChange_1D_Lag6  9920 non-null   float64\n",
      " 38  ExPost_PriceChange_1D_Lag7  9900 non-null   float64\n",
      " 39  SMA_3D                      10000 non-null  float64\n",
      " 40  SMA_5D                      9960 non-null   float64\n",
      " 41  SMA_10D                     9860 non-null   float64\n",
      " 42  Expanded_Mean               10020 non-null  float64\n",
      "dtypes: float64(34), int64(6), object(3)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Checking for null values\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null values are explainable by the feature engineering we used in Part Two.\n",
    "\n",
    "(1) ExPost_PriceChange_1D, ExPost_PriceChange_5D, ExPost_PriceChange_10D will have null values at the beginning of the time series because of the data required to make this calculation.\n",
    "\n",
    "(2) ExAnte_PriceChange_1D, ExAnte_PriceChange_3D, ExAnte_PriceChange_5D will have null values at the end of the time series because of the data required to make this calculation.\n",
    "\n",
    "(3) Lag Features (Robinhood_LagX, Percentage_Volume_LagY, ExPost_PriceChange_1D_LagZ) have starting null values because of the lagging nature.\n",
    "\n",
    "(4) Simple moving averages (SMA_3D, SMA_5D, SMA_10D) and Expanded_Mean will have null values at the beginning of the time series because of the data required to make this calculation.\n",
    "\n",
    "Since these represent just a few datapoints (< 2%), we are comfortable dropping those null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9760 entries, 10 to 10054\n",
      "Data columns (total 43 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Unnamed: 0                  9760 non-null   int64  \n",
      " 1   Date                        9760 non-null   object \n",
      " 2   Robinhood                   9760 non-null   float64\n",
      " 3   Price                       9760 non-null   float64\n",
      " 4   Volume                      9760 non-null   int64  \n",
      " 5   Ticker                      9760 non-null   object \n",
      " 6   Company                     9760 non-null   object \n",
      " 7   Percentage_Volume           9760 non-null   float64\n",
      " 8   ExPost_PriceChange_1D       9760 non-null   float64\n",
      " 9   ExPost_PriceChange_5D       9760 non-null   float64\n",
      " 10  ExPost_PriceChange_10D      9760 non-null   float64\n",
      " 11  ExAnte_PriceChange_1D       9760 non-null   float64\n",
      " 12  ExAnte_PriceChange_3D       9760 non-null   float64\n",
      " 13  ExAnte_PriceChange_5D       9760 non-null   float64\n",
      " 14  Year                        9760 non-null   int64  \n",
      " 15  Month                       9760 non-null   int64  \n",
      " 16  Day                         9760 non-null   int64  \n",
      " 17  Day_of_Week                 9760 non-null   int64  \n",
      " 18  Robinhood_Lag1              9760 non-null   float64\n",
      " 19  Robinhood_Lag2              9760 non-null   float64\n",
      " 20  Robinhood_Lag3              9760 non-null   float64\n",
      " 21  Robinhood_Lag4              9760 non-null   float64\n",
      " 22  Robinhood_Lag5              9760 non-null   float64\n",
      " 23  Robinhood_Lag6              9760 non-null   float64\n",
      " 24  Robinhood_Lag7              9760 non-null   float64\n",
      " 25  Percentage_Volume_Lag1      9760 non-null   float64\n",
      " 26  Percentage_Volume_Lag2      9760 non-null   float64\n",
      " 27  Percentage_Volume_Lag3      9760 non-null   float64\n",
      " 28  Percentage_Volume_Lag4      9760 non-null   float64\n",
      " 29  Percentage_Volume_Lag5      9760 non-null   float64\n",
      " 30  Percentage_Volume_Lag6      9760 non-null   float64\n",
      " 31  Percentage_Volume_Lag7      9760 non-null   float64\n",
      " 32  ExPost_PriceChange_1D_Lag1  9760 non-null   float64\n",
      " 33  ExPost_PriceChange_1D_Lag2  9760 non-null   float64\n",
      " 34  ExPost_PriceChange_1D_Lag3  9760 non-null   float64\n",
      " 35  ExPost_PriceChange_1D_Lag4  9760 non-null   float64\n",
      " 36  ExPost_PriceChange_1D_Lag5  9760 non-null   float64\n",
      " 37  ExPost_PriceChange_1D_Lag6  9760 non-null   float64\n",
      " 38  ExPost_PriceChange_1D_Lag7  9760 non-null   float64\n",
      " 39  SMA_3D                      9760 non-null   float64\n",
      " 40  SMA_5D                      9760 non-null   float64\n",
      " 41  SMA_10D                     9760 non-null   float64\n",
      " 42  Expanded_Mean               9760 non-null   float64\n",
      "dtypes: float64(34), int64(6), object(3)\n",
      "memory usage: 3.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a summary of the dataset we're working with.\n",
    "\n",
    "Number of observations: 9,760\n",
    "\n",
    "Number of Features: 32\n",
    "\n",
    "Feature Names: Robinhood, Ticker, Percentage_Volume, Year, Month, Day, Day_of_Week, Robinhood_LagX (1...7), Percentage_Volume_LagY (1...7), ExPost_PriceChange_1D_LagZ (1...7), SMA_3D, SMA_5D, SMA_10D, Expanded_Mean\n",
    "\n",
    "Number of Target Variables: 6\n",
    "\n",
    "Name of Target Variables: ExPost_PriceChange_1D, ExPost_PriceChange_5D, ExPost_PriceChange_10D, ExAnte_PriceChange_1D, ExAnte_PriceChange_1D, ExAnte_PriceChange_3D, ExAnte_PriceChange_5D\n",
    "\n",
    "Let's rearrange our dataframe with the features on the left and target variables on the right, and dropping any extraneous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Robinhood</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Percentage_Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Robinhood_Lag1</th>\n",
       "      <th>Robinhood_Lag2</th>\n",
       "      <th>Robinhood_Lag3</th>\n",
       "      <th>...</th>\n",
       "      <th>SMA_3D</th>\n",
       "      <th>SMA_5D</th>\n",
       "      <th>SMA_10D</th>\n",
       "      <th>Expanded_Mean</th>\n",
       "      <th>ExPost_PriceChange_1D</th>\n",
       "      <th>ExPost_PriceChange_5D</th>\n",
       "      <th>ExPost_PriceChange_10D</th>\n",
       "      <th>ExAnte_PriceChange_1D</th>\n",
       "      <th>ExAnte_PriceChange_3D</th>\n",
       "      <th>ExAnte_PriceChange_5D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150065.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>150087.0</td>\n",
       "      <td>150117.0</td>\n",
       "      <td>150592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.022812</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>0.008096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150523.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>150065.0</td>\n",
       "      <td>150087.0</td>\n",
       "      <td>150117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>0.013413</td>\n",
       "      <td>0.035233</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.023214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150750.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>150523.0</td>\n",
       "      <td>150065.0</td>\n",
       "      <td>150087.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.007773</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>0.034952</td>\n",
       "      <td>-0.002293</td>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.012143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150839.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>150750.0</td>\n",
       "      <td>150523.0</td>\n",
       "      <td>150065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>-0.002293</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.017656</td>\n",
       "      <td>-0.002403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151029.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>150839.0</td>\n",
       "      <td>150750.0</td>\n",
       "      <td>150523.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.007254</td>\n",
       "      <td>0.013569</td>\n",
       "      <td>-0.008872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Robinhood Ticker  Percentage_Volume  Year  Month  Day  Day_of_Week  \\\n",
       "0   150065.0   AAPL           0.002415  2018      7   17            1   \n",
       "1   150523.0   AAPL           0.002295  2018      7   18            2   \n",
       "2   150750.0   AAPL           0.001858  2018      7   19            3   \n",
       "3   150839.0   AAPL           0.001824  2018      7   20            4   \n",
       "4   151029.0   AAPL           0.002361  2018      7   23            0   \n",
       "\n",
       "   Robinhood_Lag1  Robinhood_Lag2  Robinhood_Lag3  ...    SMA_3D    SMA_5D  \\\n",
       "0        150087.0        150117.0        150592.0  ...  0.000735  0.001199   \n",
       "1        150065.0        150087.0        150117.0  ... -0.001617  0.002697   \n",
       "2        150523.0        150065.0        150087.0  ...  0.001706  0.000899   \n",
       "3        150750.0        150523.0        150065.0  ... -0.000001  0.000126   \n",
       "4        150839.0        150750.0        150523.0  ...  0.002123  0.000742   \n",
       "\n",
       "    SMA_10D  Expanded_Mean  ExPost_PriceChange_1D  ExPost_PriceChange_5D  \\\n",
       "0  0.002316       0.002316               0.002829               0.005779   \n",
       "1  0.003510       0.001607              -0.005484               0.013413   \n",
       "2  0.003482       0.002121               0.007773               0.004450   \n",
       "3  0.001867       0.001782              -0.002293               0.000575   \n",
       "4  0.000567       0.001718               0.000888               0.003667   \n",
       "\n",
       "   ExPost_PriceChange_10D  ExAnte_PriceChange_1D  ExAnte_PriceChange_3D  \\\n",
       "0                0.022812              -0.005484              -0.000052   \n",
       "1                0.035233               0.007773               0.006355   \n",
       "2                0.034952              -0.002293               0.005837   \n",
       "3                0.018460               0.000888               0.017656   \n",
       "4                0.005405               0.007254               0.013569   \n",
       "\n",
       "   ExAnte_PriceChange_5D  \n",
       "0               0.008096  \n",
       "1               0.023214  \n",
       "2               0.012143  \n",
       "3              -0.002403  \n",
       "4              -0.008872  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ['Robinhood', 'Ticker', 'Percentage_Volume', 'Year', 'Month', 'Day', 'Day_of_Week',\n",
    "                 'Robinhood_Lag1', 'Robinhood_Lag2', 'Robinhood_Lag3', 'Robinhood_Lag4', 'Robinhood_Lag5', 'Robinhood_Lag6', 'Robinhood_Lag7',\n",
    "                 'Percentage_Volume_Lag1', 'Percentage_Volume_Lag2', 'Percentage_Volume_Lag3', 'Percentage_Volume_Lag4', 'Percentage_Volume_Lag5', 'Percentage_Volume_Lag6', 'Percentage_Volume_Lag7',\n",
    "                 'ExPost_PriceChange_1D_Lag1', 'ExPost_PriceChange_1D_Lag2', 'ExPost_PriceChange_1D_Lag3', 'ExPost_PriceChange_1D_Lag4', 'ExPost_PriceChange_1D_Lag5', 'ExPost_PriceChange_1D_Lag6', 'ExPost_PriceChange_1D_Lag7', \n",
    "                 'SMA_3D', 'SMA_5D', 'SMA_10D', 'Expanded_Mean']\n",
    "\n",
    "target_names = ['ExPost_PriceChange_1D', 'ExPost_PriceChange_5D', 'ExPost_PriceChange_10D',\n",
    "                'ExAnte_PriceChange_1D', 'ExAnte_PriceChange_3D', 'ExAnte_PriceChange_5D']\n",
    "\n",
    "df_new = df[feature_names + target_names].reset_index(drop=True)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also convert our stock tickers categorical data to dummy variables.\n",
    "\n",
    "Although this is not necessary for some machine learning models like decision trees, we want to have the same dataset in case we want to standarize this pre-processing in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Robinhood</th>\n",
       "      <th>Percentage_Volume</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>Robinhood_Lag1</th>\n",
       "      <th>Robinhood_Lag2</th>\n",
       "      <th>Robinhood_Lag3</th>\n",
       "      <th>Robinhood_Lag4</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticker_NKE</th>\n",
       "      <th>Ticker_NVDA</th>\n",
       "      <th>Ticker_PYPL</th>\n",
       "      <th>Ticker_SNAP</th>\n",
       "      <th>Ticker_SQ</th>\n",
       "      <th>Ticker_T</th>\n",
       "      <th>Ticker_TSLA</th>\n",
       "      <th>Ticker_TWTR</th>\n",
       "      <th>Ticker_V</th>\n",
       "      <th>Ticker_ZNGA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150065.0</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>150087.0</td>\n",
       "      <td>150117.0</td>\n",
       "      <td>150592.0</td>\n",
       "      <td>150575.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150523.0</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>150065.0</td>\n",
       "      <td>150087.0</td>\n",
       "      <td>150117.0</td>\n",
       "      <td>150592.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150750.0</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>150523.0</td>\n",
       "      <td>150065.0</td>\n",
       "      <td>150087.0</td>\n",
       "      <td>150117.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150839.0</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>150750.0</td>\n",
       "      <td>150523.0</td>\n",
       "      <td>150065.0</td>\n",
       "      <td>150087.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151029.0</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>2018</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>150839.0</td>\n",
       "      <td>150750.0</td>\n",
       "      <td>150523.0</td>\n",
       "      <td>150065.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Robinhood  Percentage_Volume  Year  Month  Day  Day_of_Week  \\\n",
       "0   150065.0           0.002415  2018      7   17            1   \n",
       "1   150523.0           0.002295  2018      7   18            2   \n",
       "2   150750.0           0.001858  2018      7   19            3   \n",
       "3   150839.0           0.001824  2018      7   20            4   \n",
       "4   151029.0           0.002361  2018      7   23            0   \n",
       "\n",
       "   Robinhood_Lag1  Robinhood_Lag2  Robinhood_Lag3  Robinhood_Lag4  ...  \\\n",
       "0        150087.0        150117.0        150592.0        150575.0  ...   \n",
       "1        150065.0        150087.0        150117.0        150592.0  ...   \n",
       "2        150523.0        150065.0        150087.0        150117.0  ...   \n",
       "3        150750.0        150523.0        150065.0        150087.0  ...   \n",
       "4        150839.0        150750.0        150523.0        150065.0  ...   \n",
       "\n",
       "   Ticker_NKE  Ticker_NVDA  Ticker_PYPL  Ticker_SNAP  Ticker_SQ  Ticker_T  \\\n",
       "0           0            0            0            0          0         0   \n",
       "1           0            0            0            0          0         0   \n",
       "2           0            0            0            0          0         0   \n",
       "3           0            0            0            0          0         0   \n",
       "4           0            0            0            0          0         0   \n",
       "\n",
       "   Ticker_TSLA  Ticker_TWTR  Ticker_V  Ticker_ZNGA  \n",
       "0            0            0         0            0  \n",
       "1            0            0         0            0  \n",
       "2            0            0         0            0  \n",
       "3            0            0         0            0  \n",
       "4            0            0         0            0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.get_dummies(df_new)\n",
    "\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now ready to prepare the training and test data splitting.\n",
    "\n",
    "To prevent any training data from leaking into the test data, we should now split the data before any data normalization.\n",
    "\n",
    "Since this is a time-series and again to prevent training data from leaking into the test data, we need to do a contiguous split (no shuffling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Total_Observations = df_new.shape[0]\n",
    "Total_Stocks = 20\n",
    "Unique_Days = Total_Observations / Total_Stocks\n",
    "\n",
    "# Let's do a 75/25 split of the data\n",
    "Split = int(Unique_Days * .75)\n",
    "\n",
    "# Initializing the train/test split dataframes\n",
    "df_train = pd.DataFrame(columns = df_new.columns)\n",
    "df_test = pd.DataFrame(columns = df_new.columns)\n",
    "\n",
    "# For each stock, we will do a contiguous split of the data\n",
    "\n",
    "for stock in tickers:\n",
    "    \n",
    "    column_name = 'Ticker_' + stock\n",
    "    \n",
    "    # A contiguous split of the training and test dataframes\n",
    "    df_train = df_train.append(df_new[df_new[column_name]==1].iloc[:Split])\n",
    "    df_test = df_test.append(df_new[df_new[column_name]==1].iloc[Split:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shapes of the training and target dataframes to see if they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataframe shape: (7320, 57)\n",
      "Training size percentage: 0.75\n",
      "Test dataframe shape: (2440, 57)\n",
      "Test size percentage: 0.25\n"
     ]
    }
   ],
   "source": [
    "print('Training dataframe shape: ' + str(df_train.shape))\n",
    "print('Training size percentage: ' + str(df_train.shape[0]/df_new.shape[0]))\n",
    "\n",
    "print('Test dataframe shape: ' + str(df_test.shape))\n",
    "print('Test size percentage: ' + str(df_test.shape[0]/df_new.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look's right, so we just need to split the training and test dataframes between the explanatory (X's) and target (y's) columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X training shape: (7320, 51)\n",
      "y training shape: (7320, 6)\n",
      "X test shape: (2440, 51)\n",
      "y test shape: (2440, 6)\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.drop(target_names, axis=1)\n",
    "y_train = df_train[target_names]\n",
    "\n",
    "X_test = df_test.drop(target_names, axis=1)\n",
    "y_test = df_test[target_names]\n",
    "\n",
    "# Let's do a final shape check of the train/test split data\n",
    "print('X training shape: ' + str(X_train.shape))\n",
    "print('y training shape: ' + str(y_train.shape))\n",
    "\n",
    "print('X test shape: ' + str(X_test.shape))\n",
    "print('y test shape: ' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to apply the Standard Scaler to our training data.\n",
    "\n",
    "However, we don't need to apply it to our dummy variables so let's use a Column Transformer which excludes the transformation on the dummy columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This column transformer will apply the Standard Scalization to our non-dummy columns and pass through the dummy columns\n",
    "\n",
    "transformer = ColumnTransformer(transformers = [('standard', StandardScaler(), [0, X_train.columns.get_loc('Expanded_Mean')])],\n",
    "                                remainder = 'passthrough')\n",
    "\n",
    "# First, fitting transformer to our training data\n",
    "transformer.fit(X_train)\n",
    "\n",
    "# Finally, use the same transformer to scale our training and test data\n",
    "X_train_scaled = transformer.fit_transform(X_train)\n",
    "X_test_scaled = transformer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of this capstone project - in order to keep the notebooks for each process separate - we'll going to export the 4 dataframes (X_train, y_train, X_test, y_test) as csv's for the next part of data modeling.\n",
    "\n",
    "This step is usually not done as this process would be integrated into the data modeling process / pipeline as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_export = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_train_export.to_csv(\"../data/X_train.csv\")\n",
    "\n",
    "X_test_export = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "X_test_export.to_csv(\"../data/X_test.csv\")\n",
    "\n",
    "y_train.to_csv(\"../data/y_train.csv\")\n",
    "y_test.to_csv(\"../data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
